# -*- coding: utf-8 -*-
"""YT Gemini 2.5 Pro Podcast Audio transcription

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p3VB7BIcZ0gRP--6BCqW_dRRGHZrtguM

# Google Gemini 2.5 Pro for Audio Understanding & Transcription
"""

!pip -q install google-genai jinja2

from google.colab import userdata

GOOGLE_API_KEY=userdata.get('GOOGLE_AI_STUDIO')

import os
from google import genai
from google.genai import types

client = genai.Client(api_key=GOOGLE_API_KEY)

"""## Podcast Example

"""

from jinja2 import Template

prompt_template = Template("""Generate a transcript of the episode.

**Important Context & Instructions:**

* **Primary Speakers & Accents:** Be aware of two likely primary speakers:
    * **Declan Kennedy:** Speaks with a strong Irish accent.
    * **Interviewer:** Speaks with a strong German accent.

* **Languages:** Conversations may be in German, English, Gaelic, and other languages. There will be a wide variety of accents.

* **Unclear Words:** If you are uncertain about a word, provide your best guess followed by a percentage confidence score in brackets.
    eg: I think it was about the subsidiarity [70% confidence].

* **Multiple Speakers:** There will potentially be multiple other speakers. If you really don't know the speaker's name, identify them with a letter of the alphabet (e.g., Speaker A, Speaker B).

**Transcript Formatting:**

Include timestamps and identify speakers.

Speakers are:
{% for speaker in speakers %}- {{ speaker }}{% if not loop.last %}\n{% endif %}{% endfor %}

eg:
[00:00] Declan: Hello there.
[00:02] Interviewer: Hi Declan.

It is important to include the correct speaker names. Use the names you identified earlier.

If there is music or a short jingle playing, signify like so:
[01:02] [MUSIC] or [01:02] [JINGLE]

If you can identify the name of the music or jingle playing then use that instead, eg:
[01:02] [Firework by Katy Perry] or [01:02] [The Sofa Shop jingle]

If there is some other sound playing try to identify the sound, eg:
[01:02] [Bell ringing]

Each individual caption should be quite short, a few short sentences at most.

Signify the end of the episode with [END].

Don't use any markdown formatting, like bolding or italics.

Only use characters from the English alphabet, unless you genuinely believe foreign characters are correct.

It is important that you use the correct words and spell everything correctly. Use the context of the podcast to help.
If the hosts discuss something like a movie, book or celebrity, make sure the movie, book, or celebrity name is spelled correctly.""")

# Example of how to render the template (optional)
speakers_list = ["Declan", "Interviewer", "Guest"]
rendered_prompt = prompt_template.render(speakers=speakers_list)
print(rendered_prompt)

"""## Uploading the MP3"""

from google.colab import drive
drive.mount('/content/drive')

# path to the file to upload
file_path = "/content/drive/MyDrive/Decland_Projects/Multi-Audio/Nigeria-1965.m4a"

# Upload the file to the File API
uploaded_file = client.files.upload(file=file_path)

file_name = uploaded_file.name
print(file_name)

myfile = client.files.get(name=file_name)
print(myfile)

response = client.models.generate_content(
    model="gemini-2.5-pro-preview-06-05",
    contents=[rendered_prompt, uploaded_file],
)

print(response.text)

import re
import datetime

def timestamp_to_seconds(ts_str):
    """
    Converts an HH:MM:SS or MM:SS timestamp string to total seconds.

    Args:
        ts_str (str): Timestamp string in HH:MM:SS or MM:SS format.

    Returns:
        int or None: Total seconds from midnight, or None if parsing fails.
    """
    try:
        # Remove milliseconds if present
        ts_str = ts_str.split('.')[0]
        # Split timestamp into parts
        parts = list(map(int, ts_str.split(':')))

        if len(parts) == 3: # HH:MM:SS format
            h, m, s = parts
            return h * 3600 + m * 60 + s
        elif len(parts) == 2: # MM:SS format
            m, s = parts
            return m * 60 + s
        else:
            # Invalid number of parts
            return None
    except (ValueError, AttributeError, IndexError):
        # Return None if parsing fails for any reason
        return None

def seconds_to_timestamp(total_seconds):
    """
    Converts total seconds to an HH:MM:SS timestamp string.
    (No changes needed here, always outputs full format)

    Args:
        total_seconds (int): Total seconds from midnight.

    Returns:
        str: Timestamp string in HH:MM:SS format.
    """
    if total_seconds is None or total_seconds < 0:
        total_seconds = 0 # Default to 0 if input is invalid or negative
    # Calculate hours, minutes, and seconds
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    # Format as HH:MM:SS with leading zeros
    return f"{int(hours):02}:{int(minutes):02}:{int(seconds):02}"

def process_transcript(input_text, max_segment_duration=30):
    """
    Processes transcript text to join lines based on speaker and time.

    Joins consecutive lines if the speaker is the same AND the time elapsed
    since the start of the current segment is within max_segment_duration.
    Starts a new segment if the speaker changes OR the time limit is exceeded.
    Includes non-dialogue lines (like [MUSIC]) as separate lines.

    Args:
        input_text (str): The raw transcript text (multiline string).
        max_segment_duration (int): Maximum duration in seconds for a single
                                     speaker's segment before forcing a new
                                     timestamp. Defaults to 30.

    Returns:
        str: The processed transcript text as a multiline string.
    """
    # Use splitlines() for more robust handling of different newline characters
    lines = input_text.strip().splitlines()
    output_lines = [] # List to store the processed output lines

    # Variables to keep track of the current segment being built
    current_segment_start_ts_str = None # Timestamp string of the segment start
    current_segment_start_seconds = None # Timestamp in seconds of the segment start
    current_speaker = None               # Speaker of the current segment
    current_text_parts = []              # List of text pieces in the current segment

    # --- UPDATED Regex ---
    # Capture timestamp [HH:MM:SS] or [MM:SS], speaker, and text content.
    # Made the HH: part optional using (?:...)?
    line_regex = re.compile(r'^\[((?:\d{2}:)?\d{2}:\d{2}(?:\.\d+)?)\]\s*([^:]+?):\s*(.*)$')
    # Breakdown of timestamp part: ((?:\d{2}:)?\d{2}:\d{2}(?:\.\d+)?)
    # (                    - Start capture group 1 (full timestamp)
    #  (?:               - Start non-capturing group for HH:
    #   \d{2}:            - Match two digits and a colon (HH:)
    #  )?                - End non-capturing group, make it optional
    #  \d{2}:\d{2}        - Match MM:SS (required)
    #  (?:\.\d+)?        - Optionally match milliseconds (non-capturing)
    # )                    - End capture group 1

    for i, line in enumerate(lines):
        line = line.strip() # Remove leading/trailing whitespace
        if not line:
            continue # Skip empty lines

        match = line_regex.match(line)

        # --- Debugging Prints (Keep commented unless needed) ---
        # print(f"\nProcessing Line {i+1}: {line}")
        # if match:
        #     _ts, _spk, _txt = match.groups()
        #     _sec = timestamp_to_seconds(_ts)
        #     print(f"  Parsed: ts={_ts}, speaker='{_spk.strip()}', text='{_txt.strip()}', seconds={_sec}")
        # else:
        #     print(f"  No Match: Treating as non-dialogue.")
        # print(f"  Current Segment State: speaker='{current_speaker}', start_ts='{current_segment_start_ts_str}', start_sec={current_segment_start_seconds}")
        # --- End Debugging Prints ---

        if not match:
            # --- Handle non-standard lines ---
            if current_speaker is not None:
                segment_text = ' '.join(filter(None, current_text_parts))
                # print(f"  Finalizing previous (due to non-match): [{current_segment_start_ts_str}] {current_speaker}: {segment_text}") # DEBUG
                output_lines.append(f"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}")
                current_speaker = None
                current_text_parts = []
                current_segment_start_ts_str = None
                current_segment_start_seconds = None
            # print(f"  Adding non-dialogue line: {line}") # DEBUG
            output_lines.append(line)
            continue

        # --- Process standard dialogue lines ---
        ts_str, speaker, text = match.groups()
        speaker = speaker.strip()
        text = text.strip()
        # Use the updated function to parse timestamp
        current_seconds = timestamp_to_seconds(ts_str)

        if current_seconds is None:
             print(f"Warning: Skipping line {i+1} due to invalid timestamp format: {line}")
             continue

        # --- Logic to decide whether to start a new segment ---
        start_new_segment = False
        reason = "" # DEBUG
        if current_speaker is None:
            start_new_segment = True
            reason = "No active segment" # DEBUG
        elif speaker != current_speaker:
            start_new_segment = True
            reason = f"Speaker changed ('{speaker}' != '{current_speaker}')" # DEBUG
        # Ensure start_seconds is not None before comparison
        elif current_segment_start_seconds is not None and \
             current_seconds - current_segment_start_seconds > max_segment_duration:
            start_new_segment = True
            reason = f"Time limit exceeded ({current_seconds - current_segment_start_seconds}s > {max_segment_duration}s)" # DEBUG
        else:
            reason = "Continuing segment" # DEBUG

        # print(f"  Decision: {'Start new segment' if start_new_segment else 'Continue segment'}. Reason: {reason}") # DEBUG

        # --- Process based on the decision ---
        if start_new_segment:
            if current_speaker is not None:
                segment_text = ' '.join(filter(None, current_text_parts))
                # print(f"  Finalizing previous (due to new segment): [{current_segment_start_ts_str}] {current_speaker}: {segment_text}") # DEBUG
                output_lines.append(f"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}")

            # Use seconds_to_timestamp to ensure consistent HH:MM:SS output format
            current_segment_start_ts_str = seconds_to_timestamp(current_seconds)
            current_segment_start_seconds = current_seconds
            current_speaker = speaker
            current_text_parts = [text]
            # print(f"  Starting new segment: speaker='{speaker}', start_ts='{current_segment_start_ts_str}', start_sec={current_segment_start_seconds}, text='{text}'") # DEBUG
        else:
            # Continue the current segment
            if text:
                # print(f"  Appending text: '{text}'") # DEBUG
                current_text_parts.append(text)
            # else: # DEBUG
                # print(f"  Skipping empty text append.") # DEBUG

    # --- Finalize the very last segment ---
    if current_speaker is not None:
        segment_text = ' '.join(filter(None, current_text_parts))
        # print(f"Finalizing last segment: [{current_segment_start_ts_str}] {current_speaker}: {segment_text}") # DEBUG
        output_lines.append(f"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}")

    return "\n".join(output_lines)

processed_transcript = process_transcript(response.text, max_segment_duration=30)

processed_transcript

print(processed_transcript)

PROMPT = """Make me a set of notes in the form of bullet points  \
(with time stamps at end of each idea (in the form HH:MM:SS)) to summarize this podcast \
The bullets should be based on the idea and don't need to be sequential.
Structure the ideas with a heading and subheadings. Don't include any prefix. here is transcript below :\n\n"""

response = client.models.generate_content(
    model="gemini-2.5-pro-preview-06-05",
    contents=[PROMPT + processed_transcript],
)

print(response.text)

import IPython.display as ipd
ipd.Audio("/content/HS4830417304.mp3", autoplay=True)

